[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary",
    "section": "",
    "text": "Welcome\nHello, this is my learning diary for the Term 2 module Remotely Sensing Cities and Environments. This comprises of the weekly understanding of the classwork and materials.\nI did my Bachelors in Physical Planning from School of Planning and Architecture, Delhi, India. I have some experience in Remote Sensing, but from this module I would like to get to know the basics and the technicalities of Remote Sensing like corrections and learn Google Earth Engine (GEE)."
  },
  {
    "objectID": "1_RemoteSensingIntro.html#summary",
    "href": "1_RemoteSensingIntro.html#summary",
    "title": "1  Getting Started with Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nFirst, the applications of remote sensing were discussed, highlighting its use in land use/land cover (LULC) data, climate studies, oceanic studies, etc. We also examined which satellites are mainly used for these applications. Remote sensing utilizes two types of sensors: active and passive. Active sensors do not require an external light source, while passive sensors rely on external sources like the sun to capture reflected light. Additionally, we explored three types of atmospheric corrections commonly referenced in research papers: Rayleigh (particles smaller than the wavelength of light), Mie (particles comparable in size to the wavelength), and Non-Selective (particles larger than the wavelength). Understanding these corrections is crucial for preprocessing satellite data. Furthermore, four types of resolution must be considered when working with remote sensing data: spatial (raster size), spectral (type and number of bands), temporal (time period), and radiometric (range of possible values, e.g., 8-bit or 16-bit sensor). In the practical session, we worked with SNAP, a software application used for loading satellite imagery, performing image processing, and applying corrections."
  },
  {
    "objectID": "1_RemoteSensingIntro.html#application",
    "href": "1_RemoteSensingIntro.html#application",
    "title": "1  Getting Started with Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nRemote sensing is widely used in urban planning and environmental studies. One of the simplest applications is studying the evolution of an area over time using Google Earth, which helps analyze how the built environment grows or changes. We have also used digital elevation models (DEMs) to calculate slope and elevation, which are critical for urban planning and regulatory decisions. For instance, planning laws often restrict construction in areas with steep slopes. Additionally, DEMs help create drainage patterns, aiding in their identification and protection. Remote sensing data is also valuable in pollution studies; Sentinel-5P’s TROPOMI sensor can detect various pollutants. Another important application is flood monitoring using SAR data, as SAR can penetrate cloud cover, making it ideal for flood analysis in heavily clouded conditions."
  },
  {
    "objectID": "1_RemoteSensingIntro.html#reflection",
    "href": "1_RemoteSensingIntro.html#reflection",
    "title": "1  Getting Started with Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nI believe remote sensing data should be used to update planning laws. In my experience, many planning regulations in different Indian states are outdated. For example, remote sensing can help keep these laws current by automatically generating updated landslide hazard maps and other critical datasets like rainfall, annually. This would enhance disaster preparedness and allow planners to make more informed decisions. The potential for integrating remote sensing with automated systems is promising, and I look forward to exploring how this technology can be applied more effectively in urban planning and policy-making."
  },
  {
    "objectID": "2_Portfolio.html#xaringan-presentation-on-sentinel-5p",
    "href": "2_Portfolio.html#xaringan-presentation-on-sentinel-5p",
    "title": "2  Online Portfolio",
    "section": "2.1 Xaringan Presentation on Sentinel-5P",
    "text": "2.1 Xaringan Presentation on Sentinel-5P\nFor week 2, we were asked to prepare a presentation on any satellite."
  },
  {
    "objectID": "3_Corrections.html#summary",
    "href": "3_Corrections.html#summary",
    "title": "3  Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThe lecture was divided into two parts: types of corrections and image enhancements, and data joining, which are generally required for raw satellite imagery. Different types of corrections are necessary depending on the satellite imagery and the analysis being conducted. There are various reasons why these corrections are required, including the reflection of sunlight, accounting for Earth’s curvature and rotation, and sensor movement. These corrections can be categorized into four main types:\n\nGeometric Corrections – These are required to fix distortions that occur due to Earth’s rotation, sensor angles, and other positional inaccuracies. Methods to address these include Ground Control Points (GCPs), resampling of rasters, and regression techniques.\nAtmospheric Corrections – The atmosphere can cause image faults due to absorption and scattering, leading to discoloration or filter-like distortions. These corrections help in improving the radiometric fidelity of images.\nOrthorectification – When a sensor captures an image at an angle, especially in varying topographies, distortions occur. Orthorectification corrects these errors to ensure uniform representation of surface features.\nRadiometric Corrections – Sometimes, the radiometric resolution of a pixel does not match real-world surface values due to scattering and absorption of light or variations in sunlight intensity. These corrections help in normalizing brightness and contrast levels.\n\nThe second part of the lecture focused on data joining and enhancements. Since satellite imagery is usually divided into smaller tiles, a Point of Interest (POI) may require multiple images, necessitating the process of mosaicking—combining multiple images into a seamless dataset. An important aspect of mosaicking is ensuring uniform brightness across images to avoid noticeable seams. Enhancements are optional and depend on the specific analysis needs; they are primarily used to improve visual clarity and feature detection.\nWhile raw satellite imagery requires corrections, data joining, and enhancements, modern satellites like Sentinel and Landsat provide Analysis Ready Data (ARD), which is preprocessed to include necessary corrections. However, not all analyses require the same level of processing, making it crucial to understand and verify the changes applied to ARD before usage."
  },
  {
    "objectID": "3_Corrections.html#application",
    "href": "3_Corrections.html#application",
    "title": "3  Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\nAn example of preprocessing corrections applied to satellite imagery is in flood mapping using Sentinel-1 SAR data. Synthetic Aperture Radar (SAR) data undergoes multiple preprocessing steps, including applying orbit files, thermal noise removal, radiometric calibration, speckle noise reduction (despeckling), terrain correction, and conversion to dB values. For flood mapping, VH polarization is preferred over VV polarization as it provides better detection of water surfaces due to its reduced signal attenuation, enhanced backscatter, and improved sensitivity to water surface roughness. These preprocessing steps help create more accurate flood extent maps.\n\n\n\nTop - SAR Data before corrections, Bottom - SAR Data after corrections."
  },
  {
    "objectID": "3_Corrections.html#reflection",
    "href": "3_Corrections.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThis week’s lecture highlighted the different types of corrections and processing which can be done to the satellite imagery. Although it majorly depends on the type of analysis which is being done, we should still be aware of these different types. Majority of the open data satellite imagery have ARD which is useful and can save a lot of time, one of the major websites which hosts these data is the Google Earth Engine Catalogue. I feel like mosaicking is one of the most important one for this lecture, as it is very unlikely that we will find the POI in just one satellite imagery, so multiple imageries must be used and joining them seamlessly is very important. In mosaicking, consistency between different images is crucial. I was surprised to that in majority of the corrections, regressions was used.\nLastly, I feel like even though we can automate all the corrections to the satellite imagery, manual tweaking is still needed for visual enhancements to improve the analysis and also get more accurate results."
  },
  {
    "objectID": "3_Corrections.html#references",
    "href": "3_Corrections.html#references",
    "title": "3  Corrections",
    "section": "3.4 References",
    "text": "3.4 References\n\nNational Remote Sensing Centre (NRSC). (n.d.). Chapter 12: Flood Disaster Management. Retrieved from https://www.nrsc.gov.in/sites/default/files/pdf/ebooks/Chap_12_FloodDisasterManagement_p1.pdf\nDebraj Deka, 2023, Geospatial Analysis of Critical Infrastructure Resilience in Flood-Prone Areas: Case of Kamrup Region, Assam"
  },
  {
    "objectID": "4_Policy.html#summary",
    "href": "4_Policy.html#summary",
    "title": "4  Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nFor the case study city I have chosen Shimla City, Himachal Pradesh, India. This is a city with an area of 27 sqkm and a population density of 7600 person per sqkm as per the 2011 Census. The city’s draft Development Development plan is for the year 2041 and the expected population density is around 13000 person per sqkm.\nThe city lies in the Himalayan ranges and it faces a lot of landslides during the monsoon season, on top of that the population of the city is increasing uncontrollably. Although the current Development Plan talks about how the area is prone to natural disasters, there is no inclusion of disaster risk zones in the Land Suitability. The Development Control Regulations (DCRs) are same throughout the city irrespective of the terrain, slope, topography, but they do have green belt zones and restricted areas. A City Disaster Management Plan (CDMP) was created for the year 2021-22, but this hasn’t been implemented yet, despite the necessity. The development plan mentions how its important that disaster management is important, but there is no analysis regarding to disaster risk zones.\n\n\n\nA landslide affected area where several buildings were damaged after heavy rains, at Krishna Nagar ward in Shimla. (The Telegraph Online)\nThe CDMP even mentions that there is a need of landslide micro-zonation of the city which will help to guide and regulate the growth of Shimla and also help in the disaster prepardeness, but as of now there is no updated landlside micro-zonation of the city."
  },
  {
    "objectID": "4_Policy.html#application",
    "href": "4_Policy.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nThe city should prepare updated landslide micro-zonation maps using satellite data like DEM, rainfall data, lithology etc. This updated map will help the planners to regulate the growth. As of now there are many buildings in Shimla city which has higher FAR than the permissible FAR, this is not only illegal but is also dangerous as this can cause structural problems and can cause a chain effect during a landslide or earthquake.\nThe updated landslide micro-zonation map will not only help to prioritise regions which are falling under high risk, but it will also give the areas which are not under risk which is helpful as then the city can propose emergency disaster shelters in the areas with the lowest risk. This is essential as there are no planned/dedicated emergency shelters in the city.\nSatellite Imagery can also be used to identify the natural drainage pattern of the city and to make sure that these are protected and are not exploited. Blockage of these natural drains will increase the chances of landslide as water will seep into the soil which will decrease the structural integrity of the soil. Any construction on these drains are also dangerous and by identifying them, authorities can make sure that the regions near natural drains are not exploited."
  },
  {
    "objectID": "4_Policy.html#reflection",
    "href": "4_Policy.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nShimla City being a tourist city and famous for its high schools, the city is undergoing an uncontrolled increase of population. With this change and city being almost at its maximum capacity, the authorities should make sure that disaster management should be a top priority. They should make sure that they are prepared for these disasters and human lives and infrastructure are not lost. Remote Sensing can aid the planning and disaster management process. Rather than figuring out what to after a disaster, the use of technology can help to be prepared for this. This will also help in the urban planning of the city as implenting strict DCRs and planning laws will help the city to grow in a controlled manner."
  },
  {
    "objectID": "4_Policy.html#references",
    "href": "4_Policy.html#references",
    "title": "4  Policy",
    "section": "4.4 References",
    "text": "4.4 References\n\nKumar, A. & Pushplata (2015) ‘City profile: Shimla’, Cities, 49, pp. 149–158. Available at: https://doi.org/10.1016/j.cities.2015.08.006\nKumar, A. (2016) ‘Impact of building regulations on Indian hill towns’, HBRC Journal, 12(3), pp. 316–326. Available at: https://doi.org/10.1016/j.hbrcj.2015.02.002\nGovernment of Himachal Pradesh (2020-21) City Disaster Management Plan Shimla. Shimla: Government of Himachal Pradesh.\nTown and Country Planning Department, Himachal Pradesh (2021) Draft Development Plan Shimla Planning Area 2041. Shimla: Government of Himachal Pradesh.\nDistrict Disaster Management Authority, Shimla (2017) Shimla District Disaster Management Plan 2017. Shimla: Government of Himachal Pradesh."
  },
  {
    "objectID": "6_GEE.html#summary",
    "href": "6_GEE.html#summary",
    "title": "5  Google Earth Engine - I",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week we started with Google Earth Engine (GEE). The main reason for learning GEE is its growing popularity in research and real-world applications, primarily due to its ease of use, access to massive datasets, and fast execution. GEE excels at parallelization, allowing efficient execution and analysis of large-scale geospatial tasks. To leverage GEE effectively, we need to use server-side coding, facilitated by specific Google classes such as ee, Map, Chart, and Export. A key consideration while coding in GEE is to avoid using loops. Additionally, GEE converts all spatial data to EPSG:3857 (Web Mercator projection).\n\n\n\nGoogle Earth Engine GUI\nA few GEE-specific terminologies include: Rasters are referred to as Image, and vector datasets are called Features. The GEE interface is divided into four main sections.\nThe bottom half displays the map, layers, and allows adding geometries. The top half is further divided into three panels:\n\nThe left panel contains Scripts (for organizing files), Docs (which provides documentation on GEE classes and methods), and Assets (where users can upload and manage images, features, and CSV files).\nThe middle panel is the coding environment where JavaScript code is written.\nThe right panel consists of the Inspector (similar to the info tool in QGIS, used to check values by clicking on features), Console (for debugging and printing outputs), and Tasks (where users can monitor the progress of data uploads and exports).\n\nAlthough GEE can handle massive datasets, there are computational limits to the amount of data that can be processed at once. Therefore, for most analyses, two primary functions are used when importing an image: filterDate() and filterBounds(). These functions allow users to filter data temporally and spatially, ensuring that only relevant subsets of the dataset are analyzed efficiently."
  },
  {
    "objectID": "6_GEE.html#application",
    "href": "6_GEE.html#application",
    "title": "5  Google Earth Engine - I",
    "section": "5.2 Application",
    "text": "5.2 Application\nGEE has a wide range of applications, including downloading satellite imagery for points of interest (POIs), earth observation, geometric analysis, and the creation of web applications. One of its strengths is the ability to reproduce and verify previous research easily, leading to an exponential increase in geospatial studies utilizing GEE.\nA practical example is visualizing near real-time ozone data using Sentinel-5P’s Level 3 product with just a few lines of code from the GEE catalog:\nvar collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_O3')\n  .select('O3_column_number_density')\n  .filterDate('2019-06-01', '2019-06-05');\n\nvar band_viz = {\n  min: 0.12,\n  max: 0.15,\n  palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red']\n};\n\nMap.addLayer(collection.mean(), band_viz, 'S5P O3');\nMap.setCenter(0.0, 0.0, 2);\nThis code accesses Sentinel-5P ozone data, applies filters for specific dates, and visualizes the mean values with a predefined color palette. The dataset documentation provides details on the corrections applied, ensuring reproducibility.\nAnother example is importing feature collections (vector data) in GEE, such as Google’s Open Buildings dataset, which contains automatically generated building footprints from 50 cm resolution imagery:\nvar t = ee.FeatureCollection('GOOGLE/Research/open-buildings/v3/polygons');\n\nvar t_065_070 = t.filter('confidence &gt;= 0.65 && confidence &lt; 0.7');\nvar t_070_075 = t.filter('confidence &gt;= 0.7 && confidence &lt; 0.75');\nvar t_gte_075 = t.filter('confidence &gt;= 0.75');\n\nMap.addLayer(t_065_070, {color: 'FF0000'}, 'Buildings confidence [0.65; 0.7)');\nMap.addLayer(t_070_075, {color: 'FFFF00'}, 'Buildings confidence [0.7; 0.75)');\nMap.addLayer(t_gte_075, {color: '00FF00'}, 'Buildings confidence &gt;= 0.75');\nThis example demonstrates filtering building footprints by confidence levels. Additionally, functions like filterBounds() can be used to limit results to specific POIs. GEE also enables geometric analysis, such as creating buffers and calculating built-up areas, making it a valuable tool for urban studies and infrastructure planning."
  },
  {
    "objectID": "6_GEE.html#reflection",
    "href": "6_GEE.html#reflection",
    "title": "5  Google Earth Engine - I",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGoogle Earth Engine presents an easy approach to remote sensing by offering fast execution and seamless access to Analysis Ready Data (ARD) for widely used satellite imagery datasets. One of its most significant advantages is that it eliminates the need for extensive preprocessing steps, such as mosaicking and reprojecting multiple datasets.\nA useful feature of GEE is its ability to easily visualize and analyze satellite imagery over long time periods. Instead of manually downloading individual images for different dates which requires considerable storage and computational power, GEE enables trend analysis efficiently.\nI find GEE’s potential for creating dashboards and web applications like this Landslide Susceptibility Map of India, to be one of its most practical applications. The ability to develop interactive tools that visualize and communicate geospatial data in an accessible manner. I strongly believe that government authorities should leverage GEE to develop regional web applications, allowing not just researchers and professionals but also the general public to explore and interact with their area’s data and satellite-based insights, which will increase the general awareness."
  },
  {
    "objectID": "6_GEE.html#references",
    "href": "6_GEE.html#references",
    "title": "5  Google Earth Engine - I",
    "section": "5.4 References",
    "text": "5.4 References\n\nGoogle, COPERNICUS/S5P/NRTI/L3_O3 dataset. Available at: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_NRTI_L3_O3.\nGoogle, Google Open Buildings dataset (Version 3). Available at: https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v3_polygons.\nSirko, W., Kashubin, S., Ritter, M., Annkah, A., Bouchareb, Y.S.E., Dauphin, Y., Keysers, D., Neumann, M., Cisse, M. and Quinn, J.A. (2021) ‘Continental-scale building detection from high-resolution satellite imagery’, arXiv preprint arXiv:2107.12283. Available at: https://arxiv.org/abs/2107.12283"
  },
  {
    "objectID": "7_Classification-I.html#summary",
    "href": "7_Classification-I.html#summary",
    "title": "6  Classification - I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nFirstly, based on my experience with different GIS software, there are primarily two common types of image classification: Unsupervised and Supervised. In unsupervised classification, clustering methods automatically group pixels with similar pixel values, without the need for initial human input. These clusters must then be manually labeled into classes such as built areas, water, forests, etc. Conversely, supervised classification relies on manually created training datasets, ideally randomly generated to prevent overfitting. Classes labeled in the training dataset are then applied to classify the entire image accordingly.\nAdditionally, feature space can be utilized for image classification by plotting spectral signatures. By analyzing scatter plots, we can manually demarcate and classify images. However, understanding the spectral signatures associated with different classes is essential to perform this method effectively.\n\n\n\nSpectral signature scatter plot (50northspatial)\nIn class, we explored various classification methods, focusing particularly on classification trees and regression trees. Classification trees are used for discrete categories, while regression trees apply to continuous dependent variables. To effectively construct a regression tree, data is segmented into subsets for individual regression analyses. However, excessively dividing the data can lead to overfitting. Therefore, determining the optimal number of subsets involves calculating metrics such as the Gini impurity, which helps us to find the root of the tree. While manual selection of these splitting points using histograms is possible when clear distinctions exist, typically a more robust approach is to calculate the Sum of Squared Residuals (SSR) for potential split points, choosing the one with the lowest SSR. This iterative process continues for subsequent splits. To further mitigate overfitting, a minimum threshold for observations is recommended before splitting, aiming to achieve a balance of low bias and low variance.\nSupport Vector Machine (SVM) are used to split the data into different sections and the divider is known as the seperating hyperplane, this method is used to get the best classification whilst allowing some wrongly classified points.\nOne thing to notice is that as these classification methods get more sophisticated and accurate by using methods like Random Forest, SVM, Deep Neural Networks (DNN), the interpretability will decrease. This also means that it will be hard to debug these more sophisticated methods."
  },
  {
    "objectID": "7_Classification-I.html#applications",
    "href": "7_Classification-I.html#applications",
    "title": "6  Classification - I",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nIn Urban Planning, supervised classification of imagery is very prominent for Land Utilization and Land Cover(LULC) mapping. LULC mapping is very essential when planning for the future. It also helps to monitor the difference between the Land Use which was given to certain areas and the existing Land Utilization. Another vital application of classification is to identify the extent of informal settlement areas. This is helpful so that they can find how many unplanned housing areas there are so that they can plan accordingly (provide new housing area, redevelopment of informal settlement etc.). Classification can also be used to monitor the growth of the city through decades, which will help the urban planners to find in which side or how the city is organically growing so that they can regulate it. If this is left unwatched then it can get difficult afterwards to provide services and facilities.\n\n\n\n\n\n\nLULC map of different time period showing Urban Growth (a-1985, b-1993, c-2000, d-2008, e-2013, f-2019, Amini et. al, 2022)\nClassification is also important in climate and environmental planning, where areas of interests have to be monitored constantly and even small changes can be very critical, this can be land degradation, deforestation, glacier movement etc. Observing these climatic and environmental changes is a crucial part of sustainability and it affects all life on the planet, this helps to make global policies which can reduce the global warming effect.\nNow by using platforms like Google Earth Engine (GEE) people can automate these classification processes and monitor changes and get updated classifications as we get newer images from satellites."
  },
  {
    "objectID": "7_Classification-I.html#reflection",
    "href": "7_Classification-I.html#reflection",
    "title": "6  Classification - I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nI feel like there are so many methods for classification and it is very imporatant to know when to use which method and whether it is worth it to go for more sophisticated models like SVM and DNN which might require more technical expertise or whether simpler methods like regressions is enough. The results of an analysis for an area can defer so much by the classification methods an user uses, so it is important to know the advantages and disadvantages of these methods and which methods are often used in a particular field."
  },
  {
    "objectID": "7_Classification-I.html#references",
    "href": "7_Classification-I.html#references",
    "title": "6  Classification - I",
    "section": "6.4 References",
    "text": "6.4 References\n\nhttps://gisgeography.com/image-classification-techniques-remote-sensing/\nhttp://www.50northspatial.org/n-dimensional-spectral-feature-space-envi/\nAmini, S., Saber, M., Rabiei-Dastjerdi, H. and Homayouni, S. (2022). Urban land use and land cover change analysis using random forest classification of Landsat time series. Remote Sensing, 14(11), p.2654. Available at: https://doi.org/10.3390/rs14112654"
  },
  {
    "objectID": "8_Classification-II.html#summary",
    "href": "8_Classification-II.html#summary",
    "title": "7  Classification - II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThe lecture was a continuation of the previous week’s topic on imagery classification and assessing model accuracy. We examined various pre-classified datasets, including the European Space Agency’s (ESA) Climate Change Initiative (CCI) annual global land cover (300 m resolution) dataset (1992-2015), Dynamic World (near-real-time 10 m resolution), and Google building data. We discussed Dynamic World in detail; this AI-powered model uses Sentinel-2 imagery to classify land use and land cover (LULC) into nine distinct classes: water, trees, grass, crops, shrub, flooded vegetation, built-up areas, bare ground, and snow/ice. The classification process involves contributions from both expert and non-expert labeling, supported by sophisticated Convolutional Neural Networks (CNN). However, despite its advanced deep-learning framework, Dynamic World doesn’t necessarily outperform specialized, locally prepared LULC maps. Nevertheless, it remains valuable for monitoring land-use changes at national or international scales due to its consistent global coverage.\nWe also explored two additional image analysis techniques: Object-Based Image Analysis (OBIA) and Sub-Pixel Analysis. In OBIA, instead of classifying individual pixels, the analysis is conducted based on shapes or regions known as superpixels, identified by shape similarity or differences. Classification in OBIA can be guided by rules based on features such as distance, color, or texture. Sub-Pixel Analysis, in contrast, estimates the proportion of different land cover classes within individual pixels using spectral signatures of pure endmembers. For urban studies, the Vegetation-Impervious-Soil (VIS) model is often employed, as nearly all urban land covers can be represented through combinations of these three endmembers.\nThe second half of the lecture addressed accuracy assessments of classification results, covering three primary accuracy measures:\n\nProducer Accuracy (also known as recall) evaluates how well the model classification aligns with the expectations of those who created it.\nUser Accuracy (precision) measures how reliable the classification results are from the user’s perspective.\nOverall Accuracy provides a general measure of classification performance.\n\nIn remote sensing, achieving both high recall and high precision simultaneously is extremely challenging, as perfect predictions of LULC are practically impossible. Key terms include True Positive (model correctly predicts positive class), True Negative (model correctly predicts negative class), False Positive (model incorrectly predicts positive when it should be negative), and False Negative (model incorrectly predicts negative when it should be positive). While multiple accuracy assessment methods exist, Overall Accuracy is often preferred since it incorporates True Negatives as well. Additionally, the Receiver Operating Characteristic (ROC) curve plots True Positive Rate (TP/TP+FN) against False Positive Rate (FP/FP+TN), where an ideal classifier has an area under the curve (AUC) of 1, and a random classifier has an AUC of approximately 0.5. To prevent overfitting, various sampling strategies such as random sampling, systematic sampling, and stratified sampling can be utilized."
  },
  {
    "objectID": "8_Classification-II.html#applications",
    "href": "8_Classification-II.html#applications",
    "title": "7  Classification - II",
    "section": "7.2 Applications",
    "text": "7.2 Applications"
  },
  {
    "objectID": "8_Classification-II.html#reflection",
    "href": "8_Classification-II.html#reflection",
    "title": "7  Classification - II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThis lecture was too much information heavy. There was so many topics covered and I feel like I might have to look more into OBIA and sub pixel image analysis. Also learning about accuracy assessments are important as it will validate the model. Although there are many assessment parameters, I feel like Overall Accuracy and AUC are the best methods to validate a model. And in case of spatial things as near things are more related to distant things, it is important to choose the train and test data in such a way that the test data doesn’t overfit the train data. We can deal with this by different sampling techniques."
  },
  {
    "objectID": "8_Classification-II.html#references",
    "href": "8_Classification-II.html#references",
    "title": "7  Classification - II",
    "section": "7.4 References",
    "text": "7.4 References"
  },
  {
    "objectID": "9_SAR.html#summary",
    "href": "9_SAR.html#summary",
    "title": "8  Synthetic Aperture Radar (SAR) Data",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nOptical remote sensing imagery has limitations such as its inability to capture clear data in the presence of clouds, dust storms, or atmospheric disturbances. This is where SAR comes in. SAR sensors have their own illumination source, meaning they don’t need to rely on external illumination such as sunlight. SAR uses radar waves, which can pass through clouds and dust, making them very useful in such challenging conditions. SAR data works similarly to SONAR; the radar wave is sent from the satellite, and the reflected radar wave is observed by the sensor. This reflected radar wave is known as backscatter. Different surface textures interact differently with radar, enabling differentiation of built-up areas, land, water, etc. SAR data can even penetrate thin plastic canopies, which are often used in aircraft hangars. There are mainly three types of scattering we can observe:\n\nRough Scattering – Also known as surface scattering. Examples of textures exhibiting this type of scattering include bare earth and wavy ocean surfaces. This scattering is sensitive to VV polarization.\nVolume Scattering – This scattering is used to observe volumes, such as leaves and vegetation. It is sensitive to cross-polarizations (VH or HV).\nDouble Bounce Scattering – This scattering is observed when the radar wave bounces off structures like trees, buildings, or cliffs, reflecting back to the sensor. It is sensitive to HH polarization.\n\nSentinel-1, the most commonly used SAR satellite, only has two polarizations: VV and VH. The penetration capability of radar also varies based on the wavelength of the radar wave. Sentinel-1 uses only the C-band. Some missiles also emit C-band wavelengths upon launch; thus, after missile launches, interference occurs with Sentinel-1 data, which also uses C-band radar waves. This principle is applied defensively to destroy missiles mid-air.\n\n\n\nDifferent levels of penetration of SAR at different wavelength\nThe phase information from SAR data can be used to detect minute changes in reflections. If there is a difference in phase observed over time, it can indicate a change in elevation in the area from which the radar wave reflected. The study of such phase differences is known as interferometry. Radar data is particularly useful in change detection studies due to its consistency.\n\n\n\nHow phase difference is used in land deformation (Castellazzi, P. and Schmid, W., 2020)"
  },
  {
    "objectID": "9_SAR.html#applications",
    "href": "9_SAR.html#applications",
    "title": "8  Synthetic Aperture Radar (SAR) Data",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nSAR data is very useful in change detection and when there are challenging atmospheric conditions as optical imagery can’t be used to collect data in that case. In disaster management, SAR data is utilized in flood mapping, as during floods there is a very high probability that it might have rained so to properly the water SAR data is used. We can map the before and after of the region which flooded and then if we find the difference between both the images, we can find the flooded areas. For floods VH polarization are considered better than VV because VV is sensitive to water surface roughness. This data is also used to detect land deformations during landslides, earthquakes, volcanic activity using phase change which is very important for disaster preparedness and risk management (Elliott et al., 2016)\nSAR data can also be used in change detection which is demonstrated by Ballinger (2024) to detect the damaged buildings in conflict zones like Ukraine and Gaza. Even though SAR data does not have a high resolution, by combining this with pixel wise T-test of Sentinel-1 data. Unlike the deep learning models which needs to be trained for the specific areas in order to get a better accuracy and is very expensive, this method is more accurate and reproducible as it uses open data."
  },
  {
    "objectID": "9_SAR.html#reflection",
    "href": "9_SAR.html#reflection",
    "title": "8  Synthetic Aperture Radar (SAR) Data",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nSAR data has so many applications, it is used in places and areas where I couldn’t even imagine that SAR data can be used like change detection of damaged buildings and anti missile defence system. SAR data is so crucial where optical data can’t be used. As demonstrated in Ballinger (2024), sometimes traditional methods like pixel wise T-test can be so much efficient and accurate than deep learning models which are so expensive to build. In the age of AI, where everyone is going for AI and Deep learning models, it is shown that through few statistical methods and open data like Sentinel-1 better results can be achieved."
  },
  {
    "objectID": "9_SAR.html#references",
    "href": "9_SAR.html#references",
    "title": "8  Synthetic Aperture Radar (SAR) Data",
    "section": "8.4 References",
    "text": "8.4 References\n\nhttps://earthdata.nasa.gov/learn/backgrounders/what-is-sar\nCastellazzi, P. and Schmid, W. (2020). Ground displacements in the Lower Namoi region. NSW DPIE: CSIRO.\nElliott, J.R. et al. (2016). The role of space-based observation in understanding and responding to active tectonics and earthquakes. Nature Communications, 7, p.13844.\nBallinger, O. (2024). Open Access Battle Damage Detection via Pixel-Wise T-Test on Sentinel-1 Imagery. arXiv preprint arXiv:2405.06323."
  }
]